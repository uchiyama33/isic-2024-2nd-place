# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /callbacks: default_monitor_loss
  - override /model: image_meta_model

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["convnextv2_tiny.fcmae_ft_in22k_in1k"]

callbacks:
  early_stopping:
    patience: 50

model:
  compile: true
  # optimize_config:
  #   mode: target_decay
  #   target_name: net._orig_mod.image_model
  #   lr_base: ${model.optimizer.lr}
  #   lr_decay_coef: 0.1
  optimizer:
    lr: 5e-4
  scheduler:
    num_warmup_steps: 10
  inter_ce: true
  net:
    image_model:
      model_name: convnextv2_tiny.fcmae_ft_in22k_in1k
    meta_model:
      input_dropout: 0.3
      dropout: 0.5
    meta_pretrain_path: /workspace/logs/train/runs/0725-meta-lr1e-3-bs512-ep20/checkpoints/fold${data.fold}_epoch_010.ckpt
    dropout: 0.0
    head_mlp: true
    use_bn: true
    inter_ce: true

data:
  img_size: 288
  batch_size: 64
  transforms_version: 2

trainer:
  max_epochs: 150
  accumulate_grad_batches: 8

experiment_name: 0725-image_meta-convnextv2_tiny-lr5e-4-bs512-bn-inter_ce-metaPre10
logger:
  wandb:
    tags: ${tags}
    name: ${experiment_name}-fold${data.fold}
log_dir: ${paths.log_dir}/${task_name}/runs/${experiment_name}
hydra:
  run:
    dir: ${log_dir}
