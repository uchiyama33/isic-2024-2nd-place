# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /callbacks: default_no_es
#   - override /data: mnist
#   - override /model: mnist

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["tf_efficientnet_b0.ns_jft_in1k"]


model:
  compile: true
  scheduler:
    num_warmup_steps: 20
  optimizer:
    lr: 1e-4
  target_meta: true
  lambda_target_meta: 1
  net:
    model_name: tf_efficientnet_b0.ns_jft_in1k
    target_meta: true
    # num_classes_meta_feature_cat: [3, 2, 7] # v2

data:
  # img_size: 260
  batch_size: 128
  transforms_version: 2
  # metadata_version: 2 # v2
  neg_sampling_ratio: 5

trainer:
  max_epochs: 150
  accumulate_grad_batches: 2
  check_val_every_n_epoch : 5

experiment_name: 0815-efficientnet_b0-meta_target1-transV2-lr1e-4-warmup20-bs128_2-ep150-neg5
logger:
  wandb:
    tags: ${tags}
    name: ${experiment_name}-fold${data.fold}
log_dir: ${paths.log_dir}/${task_name}/runs/${experiment_name}
hydra:
  run:
    dir: ${log_dir}
