# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /callbacks: default_monitor_loss
  - override /data: isic2024_patient_set
  - override /model: timm_model_origin_patient_set_gat

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["convnextv2_tiny.fcmae_ft_in22k_in1k"]

callbacks:
  early_stopping:
    patience: 50

model:
  optimize_config:
    mode: target_decay
    target_name: net.image_encoder
    lr_base: ${model.optimizer.lr}
    lr_decay_coef: 0
  scheduler:
    num_warmup_steps: 0
  optimizer:
    lr: 1e-3
    weight_decay: 1e-3
  net:
    model_name: convnextv2_tiny.fcmae_ft_in22k_in1k
    projection_dim: null
    my_pretrain_path: /workspace/logs/train/runs/0728-convnextv2_tiny-meta_target-MAE-transV2-lr1e-3-bs256/checkpoints/fold${data.fold}_epoch_*.ckpt
    
data:
  img_size: 288
  batch_size: 8
  n_data_per_patient: 10
  transforms_version: 2
  neg_sampling_ratio: 20

trainer:
  # precision: bf16-mixed
  max_epochs: 250
  accumulate_grad_batches: 16
  check_val_every_n_epoch : 1
  gradient_clip_val: 2.0

experiment_name: debug-patient_set_gat-convnextv2_tiny-n10-lr1e-3-target_decay0-wd1e-3-warmup0-neg20
logger:
  wandb:
    tags: ${tags}
    name: ${experiment_name}-fold${data.fold}
log_dir: ${paths.log_dir}/${task_name}/runs/${experiment_name}
hydra:
  run:
    dir: ${log_dir}
