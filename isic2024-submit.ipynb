{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9233501,"sourceType":"datasetVersion","datasetId":5584970},{"sourceId":9233511,"sourceType":"datasetVersion","datasetId":5584980},{"sourceId":9233516,"sourceType":"datasetVersion","datasetId":5584984},{"sourceId":9239588,"sourceType":"datasetVersion","datasetId":5588950},{"sourceId":9239592,"sourceType":"datasetVersion","datasetId":5588954},{"sourceId":9244685,"sourceType":"datasetVersion","datasetId":5380624},{"sourceId":9263136,"sourceType":"datasetVersion","datasetId":5605071},{"sourceId":9266392,"sourceType":"datasetVersion","datasetId":5607576},{"sourceId":9266397,"sourceType":"datasetVersion","datasetId":5607580},{"sourceId":9274895,"sourceType":"datasetVersion","datasetId":5582343},{"sourceId":9274901,"sourceType":"datasetVersion","datasetId":5580557},{"sourceId":9282675,"sourceType":"datasetVersion","datasetId":5618780},{"sourceId":9282678,"sourceType":"datasetVersion","datasetId":5618782},{"sourceId":9300998,"sourceType":"datasetVersion","datasetId":5631660},{"sourceId":9328980,"sourceType":"datasetVersion","datasetId":5380551},{"sourceId":9328981,"sourceType":"datasetVersion","datasetId":5380552},{"sourceId":9328992,"sourceType":"datasetVersion","datasetId":5652154},{"sourceId":9329682,"sourceType":"datasetVersion","datasetId":5652618},{"sourceId":9332429,"sourceType":"datasetVersion","datasetId":5654714},{"sourceId":9332436,"sourceType":"datasetVersion","datasetId":5654720}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# src, configs\n!cp -r /kaggle/input/isic2024-src /kaggle/working; mv /kaggle/working/isic2024-src /kaggle/working/src\n!ln -s /kaggle/input/isic2024-configs /kaggle/working/configs\n\n# train logs\n!mkdir -p /kaggle/working/logs/train/runs\n# !ln -s /kaggle/input/0821-beitv2-base-tsgkf/0821-beitv2_base-sep_head-transV8-lr1e-3-target_decay001-warmup50-wd1e-2-bs32_8-mixup-ep100-neg3-tsgkf /kaggle/working/logs/train/runs/\n# !ln -s /kaggle/input/0821-convnextv2-tiny-meta-target03-tsgkf/0821-convnextv2_tiny-meta_target03-transV2-lr1e-3-target_decay001-bs128_2-ep100-neg5-tsgkf /kaggle/working/logs/train/runs/\n# !ln -s /kaggle/input/0821-eva02-small-tsgkf/0821-eva02_small-sep_head-transV6-lr1e-3-target_decay001-warmup50-wd1e-2-drop01-bs32_8-ep80-neg3-tsgkf /kaggle/working/logs/train/runs/\n# !ln -s /kaggle/input/0821-image-meta-efficientnet-b0-tsgkf/0821-image_meta-efficientnet_b0-lr5e-4-bs256-ep50-neg5-tsgkf /kaggle/working/logs/train/runs/\n# !ln -s /kaggle/input/0821-swinv2-small-tsgkf/0821-swinv2_small-transV2-lr1e-3-target_decay001-bs32_8-drop01-ep200-neg3-tsgkf /kaggle/working/logs/train/runs/\n# !ln -s /kaggle/input/0822-tip-frozen-convnextv2-nano/0822-tip_frozen-convnextv2_nano_l2d192h8-tabV3-transV8-lr5e-4-warmup50-bs_64_8-neg50-ep200-tsgkf-lr1e-3-transV2-ep30 /kaggle/working/logs/train/runs/\n# !ln -s  /kaggle/working/logs/train/runs/\n\n# train all data logs\n!mkdir -p /kaggle/working/logs/train_all_data/runs\n!ln -s /kaggle/input/train-all-data-0821-beitv2-base/0821-beitv2_base-sep_head-transV8-lr1e-3-target_decay001-warmup50-wd1e-2-bs32_8-mixup-ep100-neg3-tsgkf /kaggle/working/logs/train_all_data/runs/\n!ln -s /kaggle/input/train-all-data-0821-convnextv2-tiny-meta-t03-tsgkf/0821-convnextv2_tiny-meta_target03-transV2-lr1e-3-target_decay001-bs128_2-ep100-neg5-tsgkf /kaggle/working/logs/train_all_data/runs/\n!ln -s /kaggle/input/train-all-data-0821-eva02-small/0821-eva02_small-sep_head-transV6-lr1e-3-target_decay001-warmup50-wd1e-2-drop01-bs32_8-ep80-neg3-tsgkf /kaggle/working/logs/train_all_data/runs/\n!ln -s /kaggle/input/train-all-data-0824-eva02-small/0824-eva02_small-sep_head-transV8-lr1e-3-target_decay0008-warmup50-wd1e-2-drop01-bs32_8-ep80-neg3-cluster7t5-tsgkf /kaggle/working/logs/train_all_data/runs/\n!ln -s /kaggle/input/train-all-data-0824-swinv2-small/0824-swinv2_small-transV2-lr1e-3-target_decay001-bs32_8-drop01-ep200-neg3-cluster7t5-tsgkf /kaggle/working/logs/train_all_data/runs/\n!ln -s /kaggle/input/train-all-data-0825-tip-onlyimage-cnv2-n-bs64-2/0825-tip_finetune_onlyImage-convnextv2_nano_scratch_l2d192h8-tabV3-transV8-lr5e-4-warmup50-bs_64_8-neg50-ep200-tsgkf-lr1e-3-warmup5-bs64_2-transV2-ep80 /kaggle/working/logs/train_all_data/runs/\n!ln -s /kaggle/input/train-all-data-0827-deit3-small/0827-deit3_small-transV2-lr1e-3-target_decay001-bs32_8-ep200-neg3-tsgkf /kaggle/working/logs/train_all_data/runs/\n!ln -s /kaggle/input/train-all-data-0828-resnext50/0828-resnext50-transV2-lr1e-3-target_decay001-bs32_8-ep200-neg3-cluster7t5-tsgkf /kaggle/working/logs/train_all_data/runs/\n!ln -s /kaggle/input/train-all-data-0827-tip-onlyimage-swin-tiny-bs64-2/0827-tip_finetune_onlyImage-swin_tiny_scratch_l2d192h8-tabV3-transV8-lr5e-4-warmup50-bs_64_8-neg50-ep200-tsgkf-lr1e-3-warmup5-bs_64_2-transV8-ep80 /kaggle/working/logs/train_all_data/runs/\n# !ln -s  /kaggle/working/logs/train_all_data/runs/\n\n!mkdir -p /kaggle/working/logs/gbdt/runs\n!ln -s /kaggle/input/0906-9nns-18types-fev7-s5/0906-9NNs-18types-feV7-s5 /kaggle/working/logs/gbdt/runs/\n!ln -s /kaggle/input/0906-9nns-18types-fev7-s5-tuning-weights/0906-9NNs-18types-feV7-s5-tuning_weights /kaggle/working/logs/gbdt/runs/\n# for rootutils\n!touch /kaggle/working/.project-root\n# コンペデータ\n!mkdir /kaggle/working/data\n!ln -s /kaggle/input/isic-2024-challenge /kaggle/working/data/isic-2024-challenge","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-01T23:16:58.991425Z","iopub.execute_input":"2024-09-01T23:16:58.992032Z","iopub.status.idle":"2024-09-01T23:17:17.839427Z","shell.execute_reply.started":"2024-09-01T23:16:58.992004Z","shell.execute_reply":"2024-09-01T23:17:17.838227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbdt_params = \"0906-9NNs-18types-feV7-s5-tuning_weights\"\nbatch_size_pred=128\n# tta=False\nDEBUG_WITH_TRAIN_DATA = False\naverage = \"simple\"\nuse_model_dnn = \"all_data\"\nuse_model_gbdt = \"all_data\"\nuse_shina_models = False\n\nassert average in [\"simple\", \"rank\"]\nassert use_model_dnn in [\"kfold\", \"all_data\"]\nassert use_model_gbdt in [\"kfold\", \"all_data\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-01T23:17:17.841444Z","iopub.execute_input":"2024-09-01T23:17:17.841782Z","iopub.status.idle":"2024-09-01T23:17:17.848442Z","shell.execute_reply.started":"2024-09-01T23:17:17.841753Z","shell.execute_reply":"2024-09-01T23:17:17.847264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!cd /kaggle/input/isic2024-pip; pip install --no-index --find-links=./packages -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-09-01T23:17:17.849625Z","iopub.execute_input":"2024-09-01T23:17:17.849969Z","iopub.status.idle":"2024-09-01T23:19:19.103126Z","shell.execute_reply.started":"2024-09-01T23:17:17.849926Z","shell.execute_reply":"2024-09-01T23:19:19.101931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import hydra\nimport rootutils\nimport joblib\nimport os\nfrom lightning import LightningDataModule, LightningModule, Trainer\nfrom hydra import compose, initialize\nfrom pathlib import Path\nfrom glob import glob\nimport numpy as np\nimport torch\nimport pandas as pd\nimport lightgbm as lgb\nimport catboost as cb\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\nos.chdir(\"/kaggle/working/src\")\n\nrootutils.setup_root(Path().resolve(), indicator=\".project-root\", pythonpath=True)\n\nfrom src.utils import RankedLogger\nfrom src.isic_utils.feature_engineering_for_stacking import feature_engineering_for_stacking\nfrom src.isic_utils.utils import comp_score, preprocess_df\nfrom src.isic_utils.feature_engineering import feature_engineering_new\nfrom src.isic_utils.gbdt_models import GBDTModels\n\nroot = os.environ[\"PROJECT_ROOT\"]\nlog = RankedLogger(__name__, rank_zero_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T23:19:19.105745Z","iopub.execute_input":"2024-09-01T23:19:19.106468Z","iopub.status.idle":"2024-09-01T23:19:32.862084Z","shell.execute_reply.started":"2024-09-01T23:19:19.10643Z","shell.execute_reply":"2024-09-01T23:19:32.861105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load config\nwith initialize(version_base=None, config_path=\"configs\"):\n    cfg = compose(\n        config_name=\"gbdt\",\n        overrides=[f\"gbdt_params={gbdt_params}\"],\n        return_hydra_config=True,\n    )\n    cfg.paths.output_dir = \"${hydra.runtime.output_dir}\"\n    cfg.paths.work_dir = \"${hydra.runtime.cwd}\"\n    cfg.hydra.run.dir = cfg.log_dir\n    cfg.hydra.runtime.output_dir = cfg.hydra.run.dir\n\nif DEBUG_WITH_TRAIN_DATA:\n    cfg.data.hdf5_test_name=\"train-image.hdf5\"\n    cfg.data.meta_csv_test_name=\"train-metadata.csv\"\n    \n# prepare data\ndf_train = pd.read_csv(os.path.join(cfg.data.data_dir, cfg.data.meta_csv_train_name))\ndf_test = pd.read_csv(os.path.join(cfg.data.data_dir, cfg.data.meta_csv_test_name))\n\ndf_train, feature_cols, cat_cols = feature_engineering_new(df_train, version=cfg.gbdt_params.version_fe)\ndf_test, _, _ = feature_engineering_new(df_test, version=cfg.gbdt_params.version_fe)\ndf_train, df_test, feature_cols, cat_cols = preprocess_df(df_train, df_test, feature_cols, cat_cols)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T23:19:32.86335Z","iopub.execute_input":"2024-09-01T23:19:32.86399Z","iopub.status.idle":"2024-09-01T23:28:51.796368Z","shell.execute_reply.started":"2024-09-01T23:19:32.86395Z","shell.execute_reply":"2024-09-01T23:28:51.795222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\ndel df_train\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.distributed as dist\nimport torch.multiprocessing as mp\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nfrom torch.utils.data import DataLoader, Dataset, DistributedSampler\nimport tempfile\nfrom tqdm.notebook import tqdm\nimport gc\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n\ndef cleanup():\n    dist.destroy_process_group()\n\ndef inference(rank, world_size, temp_dir, cfg):\n    print(f\"Running inference on rank {rank}.\")\n    setup(rank, world_size)\n    \n    for dnn_run in cfg.gbdt_params.dnn_predictions:\n        with initialize(version_base=None, config_path=\"configs\"):\n            cfg_dnn = compose(\n                config_name=\"train\",\n                overrides=[f\"experiment={dnn_run.name}\"],\n                return_hydra_config=True,\n            )\n            cfg_dnn.paths.output_dir = \"${hydra.runtime.output_dir}\"\n            cfg_dnn.paths.work_dir =  \"${hydra.runtime.cwd}\"\n            cfg_dnn.hydra.run.dir = cfg_dnn.log_dir\n            cfg_dnn.hydra.runtime.output_dir = cfg_dnn.hydra.run.dir\n\n        if cfg_dnn.model.net.get(\"pretrained\"):\n            cfg_dnn.model.net.pretrained=False\n        if cfg_dnn.model.net.get(\"my_pretrain_path\"):\n            cfg_dnn.model.net.my_pretrain_path=None\n        if cfg_dnn.model.net.get(\"image_model\"):\n            if cfg_dnn.model.net.image_model.get(\"pretrained\"):\n                cfg_dnn.model.net.image_model.pretrained=False\n            if cfg_dnn.model.net.image_model.get(\"my_pretrain_path\"):\n                cfg_dnn.model.net.image_model.my_pretrain_path=None\n        if cfg_dnn.model.net.get(\"meta_pretrain_path\"):\n            cfg_dnn.model.net.meta_pretrain_path=None\n        if cfg_dnn.model.net.get(\"image_pretrain_path\"):\n            cfg_dnn.model.net.image_pretrain_path=None\n                        \n        if cfg_dnn.model.net.get(\"ckpt_path\"):\n            cfg_dnn.model.net.ckpt_path=None\n        if cfg_dnn.model.net.get(\"encoder_image\"):\n            cfg_dnn.model.net.encoder_image.pretrained=False\n            \n        cfg_dnn.data.num_workers = 2\n#         cfg_dnn.model.tta=tta\n    \n        if DEBUG_WITH_TRAIN_DATA:\n            cfg_dnn.data.hdf5_test_name=\"train-image.hdf5\"\n            cfg_dnn.data.meta_csv_test_name=\"train-metadata.csv\"\n\n        datamodule: LightningDataModule = hydra.utils.instantiate(cfg_dnn.data)\n        datamodule.setup(\"predict\")\n        dataset = datamodule.data_pred\n        \n        # データセットとデータローダーの設定\n        sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n        dataloader = DataLoader(dataset, batch_size=batch_size_pred, sampler=sampler, num_workers=2)\n\n        ckpt_paths = []\n        for fold in range(cfg_dnn.data.n_fold):\n            if fold == 0:\n                ckpt_name = \"last.ckpt\"\n            else:\n                ckpt_name = f\"last-v{fold}.ckpt\"\n            ckpt_paths.append(glob(os.path.join(cfg_dnn.paths.output_dir, \"checkpoints\", ckpt_name))[0])\n\n        # モデルの設定\n        model: LightningModule = hydra.utils.instantiate(cfg_dnn.model)\n        model = model.to(rank).eval()\n        if cfg_dnn.model.compile:\n            model.net = torch.compile(model.net)\n\n        for fold, ckpt_path in enumerate(ckpt_paths):\n            model.load_state_dict(torch.load(ckpt_path)[\"state_dict\"])\n        #     model = DDP(model.net, device_ids=[rank])\n            net = model.net\n\n            # 推論の実行\n            net.eval()\n            all_predictions = []\n            ids = []\n            with torch.inference_mode():\n                with torch.cuda.amp.autocast():\n                    for data in tqdm(dataloader, desc=f\"rank_{rank}, fold_{fold}\"):\n                        if cfg_dnn.model._target_ == \"src.models.isic2024_module_tip_finetune.ISIC2024LitModuleTIPFinetune\":\n                            logits = net(data[\"image\"].to(rank), data[\"tabular\"].to(rank))\n                        else:\n                            if cfg_dnn.model.get(\"use_image\") and cfg_dnn.model.get(\"use_metadata\"):\n                                logits = net(data[\"image\"].to(rank), data[\"metadata_num\"].to(rank), data[\"metadata_cat\"].to(rank))\n                            else: #elif cfg.model.use_image:\n                                logits = net(data[\"image\"].to(rank))\n                        \n                        \n                        if cfg.gbdt_params.use_logits:\n                            preds = logits[:, 1]\n                        else:\n                            preds = torch.softmax(logits, dim=1)[:, 1]\n                        all_predictions.append(preds.cpu())\n                        ids.append(data[\"isic_id\"])\n\n            all_predictions = torch.cat(all_predictions)\n            ids = np.concatenate(ids)\n\n            # 推論結果をファイルに保存\n            temp_file = os.path.join(temp_dir, f\"predictions_{dnn_run.name}_rank_{rank}_fold_{fold}.pt\")\n            torch.save(all_predictions, temp_file)\n            temp_file_id = os.path.join(temp_dir, f\"ids_{dnn_run.name}_rank_{rank}_fold_{fold}.npy\")\n            np.save(temp_file_id, ids)\n\n            print(f\"{dnn_run.name}, rank {rank}, fold {fold} finished inference with predictions saved to {temp_file}, {temp_file_id}\")\n            \n        del all_predictions, ids, datamodule, dataset, model, net, sampler, dataloader\n        gc.collect()\n    \n    \ndef inference_mp(cfg):\n    world_size = 2\n\n    processes = []\n    temp_dir = tempfile.mkdtemp()\n    print(f\"Temporary directory for storing predictions: {temp_dir}\")\n    for rank in range(world_size):\n        p = mp.Process(\n            target=inference, args=(rank, world_size, temp_dir, cfg)\n        )\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()\n\n    dnn_run_name_list = []\n    df_dnn_preds_list = []\n    for dnn_run in cfg.gbdt_params.dnn_predictions:\n        df_preds_list = []\n        for fold in range(cfg.data.n_fold):\n            all_predictions = []\n            all_ids = []\n            for rank in range(world_size):\n                temp_file = os.path.join(temp_dir, f\"predictions_{dnn_run.name}_rank_{rank}_fold_{fold}.pt\")\n                predictions = torch.load(temp_file)\n                temp_file_id = os.path.join(temp_dir, f\"ids_{dnn_run.name}_rank_{rank}_fold_{fold}.npy\")\n                ids = np.load(temp_file_id)\n                all_predictions.append(predictions)\n                all_ids.append(ids)\n\n            # 結果を1つのテンソルに結合\n            all_predictions = torch.cat(all_predictions)\n            all_ids = np.concatenate(all_ids)\n            df_preds = pd.DataFrame({\"isic_id\": all_ids, \"target\": all_predictions})\n            df_preds = df_preds.drop_duplicates(subset=[\"isic_id\"])\n            df_preds_list.append(df_preds)\n            \n        df_dnn_preds_list.append(concat_df_preds(df_preds_list))\n        dnn_run_name_list.append(dnn_run.name)\n        \n    return df_dnn_preds_list, dnn_run_name_list\n\n\ndef concat_df_preds(df_preds_list):\n    df_preds = df_preds_list[0].rename({\"target\": \"predictions\"} ,axis=\"columns\")\n    for k, _df_preds in enumerate(df_preds_list[1:], start=1):\n        df_preds = df_preds.merge(_df_preds.rename({\"target\": \"predictions\"} ,axis=\"columns\"), how=\"left\", on=\"isic_id\", suffixes=(\"\", f\"_{k}\"))\n    df_preds = df_preds.rename({\"predictions\": \"predictions_0\"}, axis=\"columns\")\n    \n    return df_preds","metadata":{"execution":{"iopub.status.busy":"2024-08-26T16:04:53.24092Z","iopub.execute_input":"2024-08-26T16:04:53.241255Z","iopub.status.idle":"2024-08-26T16:04:53.27615Z","shell.execute_reply.started":"2024-08-26T16:04:53.24123Z","shell.execute_reply":"2024-08-26T16:04:53.275111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_all_data(rank, world_size, temp_dir, cfg):\n    print(f\"Running inference on rank {rank}.\")\n    setup(rank, world_size)\n    \n    for dnn_run in cfg.gbdt_params.dnn_predictions:\n        with initialize(version_base=None, config_path=\"configs\"):\n            cfg_dnn = compose(\n                config_name=\"train\",\n                overrides=[f\"experiment={dnn_run.name}\"],\n                return_hydra_config=True,\n            )\n            cfg_dnn.task_name = \"train_all_data\"\n            cfg_dnn.paths.output_dir = \"${hydra.runtime.output_dir}\"\n            cfg_dnn.paths.work_dir =  \"${hydra.runtime.cwd}\"\n            cfg_dnn.hydra.run.dir = cfg_dnn.log_dir\n            cfg_dnn.hydra.runtime.output_dir = cfg_dnn.hydra.run.dir\n\n        if cfg_dnn.model.net.get(\"pretrained\"):\n            cfg_dnn.model.net.pretrained=False\n        if cfg_dnn.model.net.get(\"my_pretrain_path\"):\n            cfg_dnn.model.net.my_pretrain_path=None\n        if cfg_dnn.model.net.get(\"image_model\"):\n            if cfg_dnn.model.net.image_model.get(\"pretrained\"):\n                cfg_dnn.model.net.image_model.pretrained=False\n            if cfg_dnn.model.net.image_model.get(\"my_pretrain_path\"):\n                cfg_dnn.model.net.image_model.my_pretrain_path=None\n        if cfg_dnn.model.net.get(\"meta_pretrain_path\"):\n            cfg_dnn.model.net.meta_pretrain_path=None\n        if cfg_dnn.model.net.get(\"image_pretrain_path\"):\n            cfg_dnn.model.net.image_pretrain_path=None\n                        \n        if cfg_dnn.model.net.get(\"ckpt_path\"):\n            cfg_dnn.model.net.ckpt_path=None\n        if cfg_dnn.model.net.get(\"encoder_image\"):\n            cfg_dnn.model.net.encoder_image.pretrained=False\n            \n        cfg_dnn.data.num_workers = 2\n#         cfg_dnn.model.tta=tta\n    \n        if DEBUG_WITH_TRAIN_DATA:\n            cfg_dnn.data.hdf5_test_name=\"train-image.hdf5\"\n            cfg_dnn.data.meta_csv_test_name=\"train-metadata.csv\"\n\n        datamodule: LightningDataModule = hydra.utils.instantiate(cfg_dnn.data)\n        datamodule.setup(\"predict\")\n        dataset = datamodule.data_pred\n        \n        # データセットとデータローダーの設定\n        sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n        dataloader = DataLoader(dataset, batch_size=batch_size_pred, sampler=sampler, num_workers=2)\n\n        ckpt_name = \"last.ckpt\"\n        print(os.path.join(cfg_dnn.paths.output_dir, \"checkpoints\", ckpt_name))\n        ckpt_path = glob(os.path.join(cfg_dnn.paths.output_dir, \"checkpoints\", ckpt_name))[0]\n\n        # モデルの設定\n        model: LightningModule = hydra.utils.instantiate(cfg_dnn.model)\n        model = model.to(rank).eval()\n        if cfg_dnn.model.compile:\n            model.net = torch.compile(model.net)\n\n        model.load_state_dict(torch.load(ckpt_path)[\"state_dict\"])\n    #     model = DDP(model.net, device_ids=[rank])\n        net = model.net\n\n        # 推論の実行\n        net.eval()\n        all_predictions = []\n        ids = []\n        with torch.inference_mode():\n            with torch.cuda.amp.autocast():\n                for data in tqdm(dataloader, desc=f\"rank_{rank}\"):\n                    if cfg_dnn.model._target_ == \"src.models.isic2024_module_tip_finetune.ISIC2024LitModuleTIPFinetune\":\n                        logits = net(data[\"image\"].to(rank), data[\"tabular\"].to(rank))\n                    else:\n                        if cfg_dnn.model.get(\"use_image\") and cfg_dnn.model.get(\"use_metadata\"):\n                            logits = net(data[\"image\"].to(rank), data[\"metadata_num\"].to(rank), data[\"metadata_cat\"].to(rank))\n                        else: #elif cfg.model.use_image:\n                            logits = net(data[\"image\"].to(rank))\n\n\n                    if cfg.gbdt_params.use_logits:\n                        preds = logits[:, 1]\n                    else:\n                        preds = torch.softmax(logits, dim=1)[:, 1]\n                    all_predictions.append(preds.cpu())\n                    ids.append(data[\"isic_id\"])\n\n        all_predictions = torch.cat(all_predictions)\n        ids = np.concatenate(ids)\n\n        # 推論結果をファイルに保存\n        temp_file = os.path.join(temp_dir, f\"predictions_{dnn_run.name}_rank_{rank}.pt\")\n        torch.save(all_predictions, temp_file)\n        temp_file_id = os.path.join(temp_dir, f\"ids_{dnn_run.name}_rank_{rank}.npy\")\n        np.save(temp_file_id, ids)\n\n        print(f\"{dnn_run.name}, rank {rank} finished inference with predictions saved to {temp_file}, {temp_file_id}\")\n            \n        del all_predictions, ids, datamodule, dataset, model, net, sampler, dataloader\n        gc.collect()\n    \n    \ndef inference_mp_all_data(cfg):\n    world_size = 2\n\n    processes = []\n    temp_dir = tempfile.mkdtemp()\n    print(f\"Temporary directory for storing predictions: {temp_dir}\")\n    for rank in range(world_size):\n        p = mp.Process(\n            target=inference_all_data, args=(rank, world_size, temp_dir, cfg)\n        )\n        p.start()\n        processes.append(p)\n\n    for p in processes:\n        p.join()\n\n    dnn_run_name_list = []\n    df_dnn_preds_list = []\n    for dnn_run in cfg.gbdt_params.dnn_predictions:\n        all_predictions = []\n        all_ids = []\n        for rank in range(world_size):\n            temp_file = os.path.join(temp_dir, f\"predictions_{dnn_run.name}_rank_{rank}.pt\")\n            predictions = torch.load(temp_file)\n            temp_file_id = os.path.join(temp_dir, f\"ids_{dnn_run.name}_rank_{rank}.npy\")\n            ids = np.load(temp_file_id)\n            all_predictions.append(predictions)\n            all_ids.append(ids)\n\n        # 結果を1つのテンソルに結合\n        all_predictions = torch.cat(all_predictions)\n        all_ids = np.concatenate(all_ids)\n        df_preds = pd.DataFrame({\"isic_id\": all_ids, \"target\": all_predictions})\n        df_preds = df_preds.drop_duplicates(subset=[\"isic_id\"])\n        df_preds = df_preds.rename({\"target\": dnn_run.name} ,axis=\"columns\")\n\n        df_dnn_preds_list.append(df_preds)\n        dnn_run_name_list.append(dnn_run.name)\n        \n    return df_dnn_preds_list, dnn_run_name_list","metadata":{"execution":{"iopub.status.busy":"2024-08-26T16:04:53.504141Z","iopub.execute_input":"2024-08-26T16:04:53.504439Z","iopub.status.idle":"2024-08-26T16:04:53.531829Z","shell.execute_reply.started":"2024-08-26T16:04:53.504415Z","shell.execute_reply":"2024-08-26T16:04:53.530748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_model_dnn == \"kfold\":\n    df_dnn_preds_list, dnn_run_name_list = inference_mp(cfg)\n    # fold平均算出\n    for run_name, df_preds in zip(dnn_run_name_list, df_dnn_preds_list):\n        df_preds[run_name] = df_preds[['predictions_0', 'predictions_1', 'predictions_2', 'predictions_3', 'predictions_4']].mean(1)\n        df_test = df_test.merge(df_preds[[\"isic_id\", run_name]], how=\"left\", on=\"isic_id\")\n        \nelif use_model_dnn == \"all_data\":\n    df_dnn_preds_list, dnn_run_name_list = inference_mp_all_data(cfg)\n    for run_name, df_preds in zip(dnn_run_name_list, df_dnn_preds_list):\n        df_test = df_test.merge(df_preds[[\"isic_id\", run_name]], how=\"left\", on=\"isic_id\")\n        \nfeature_cols += dnn_run_name_list","metadata":{"execution":{"iopub.status.busy":"2024-08-26T16:04:53.722631Z","iopub.execute_input":"2024-08-26T16:04:53.722922Z","iopub.status.idle":"2024-08-26T16:13:27.976023Z","shell.execute_reply.started":"2024-08-26T16:04:53.722899Z","shell.execute_reply":"2024-08-26T16:13:27.974765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shina's models\nif use_shina_models:\n    !python /kaggle/input/edgenext-scripts/edgenext_fp16_mod.py 5 1\n    !mv submission.csv submission_edgenext0822.csv\n\n    !python /kaggle/input/edgenext-scripts/edgenext_128_fp16_mod.py 5 1\n    !mv submission.csv submission_edgenext0822_128.csv\n\n    df_preds = pd.read_csv(\"submission_edgenext0822.csv\")\n    df_preds = df_preds[[\"isic_id\", \"target\"]].rename({\"target\": \"edgenext0822\"}, axis=1)\n    df_test = df_test.merge(df_preds, how=\"left\", on=\"isic_id\")\n\n    df_preds = pd.read_csv(\"submission_edgenext0822_128.csv\")\n    df_preds = df_preds[[\"isic_id\", \"target\"]].rename({\"target\": \"edgenext0822_128\"}, axis=1)\n    df_test = df_test.merge(df_preds, how=\"left\", on=\"isic_id\")\n\n    feature_cols += [\"edgenext0822\", \"edgenext0822_128\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:50:06.45184Z","iopub.execute_input":"2024-08-31T09:50:06.452252Z","iopub.status.idle":"2024-08-31T09:50:56.181883Z","shell.execute_reply.started":"2024-08-31T09:50:06.452225Z","shell.execute_reply":"2024-08-31T09:50:56.180827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DBGT prediction\nif use_model_gbdt == \"kfold\":\n    predictions_list = []\n    for fold in range(cfg.data.n_fold):\n        save_file_path = os.path.join(cfg.log_dir, f\"model_{fold}.joblib\")\n        model = joblib.load(save_file_path)\n\n        preds = model.predict(df_test)\n        predictions_list.append(preds)\n        \n        del model\n        gc.collect()\n\n    predictions_list = np.stack(predictions_list)\n\n    if average == \"rank\":\n        df_rank = pd.DataFrame(predictions_list.T).rank()\n        n_preds = df_rank.shape[1]\n        df_rank[\"rank_sum\"] = np.sum(df_rank[col] for col in df_rank.columns)\n        df_rank[\"target\"] = df_rank[\"rank_sum\"] / (n_preds * df_rank.shape[0])\n        target = df_rank[\"target\"].values\n    elif average == \"simple\":\n        target = predictions_list.mean(0)\n    \nelif use_model_gbdt == \"all_data\":\n    save_file_path = os.path.join(cfg.log_dir, f\"model_all_data.joblib\")\n    model = joblib.load(save_file_path)\n    target = model.predict(df_test)\n    \n    del model\n    gc.collect()\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-26T16:13:27.97824Z","iopub.execute_input":"2024-08-26T16:13:27.978673Z","iopub.status.idle":"2024-08-26T16:13:30.460862Z","shell.execute_reply.started":"2024-08-26T16:13:27.978632Z","shell.execute_reply":"2024-08-26T16:13:30.4594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert not DEBUG_WITH_TRAIN_DATA\ndf_submit = pd.DataFrame({\"isic_id\":df_test[\"isic_id\"],\"target\":target})\ndf_submit.to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T16:13:30.46155Z","iopub.status.idle":"2024-08-26T16:13:30.4619Z","shell.execute_reply.started":"2024-08-26T16:13:30.461731Z","shell.execute_reply":"2024-08-26T16:13:30.461745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display\n\ndisplay(df_submit.head())","metadata":{"execution":{"iopub.status.busy":"2024-08-26T16:13:30.463197Z","iopub.status.idle":"2024-08-26T16:13:30.46352Z","shell.execute_reply.started":"2024-08-26T16:13:30.46336Z","shell.execute_reply":"2024-08-26T16:13:30.463374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}